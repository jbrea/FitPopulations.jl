var documenterSearchIndex = {"docs":
[{"location":"rl/#Fitting-a-Q-Learner","page":"Fitting a Q-Learner","title":"Fitting a Q-Learner","text":"","category":"section"},{"location":"rl/","page":"Fitting a Q-Learner","title":"Fitting a Q-Learner","text":"We define a Q-Learner that explores an environment with 10 states and 3 actions with softmax policy.","category":"page"},{"location":"rl/","page":"Fitting a Q-Learner","title":"Fitting a Q-Learner","text":"using LaplacianExpectationMaximization\nusing ConcreteStructs\nimport LogExpFunctions: softplus, logistic\n\n@concrete struct QLearner\n    q\nend\nQLearner() = QLearner(zeros(10, 3))\n\nfunction LaplacianExpectationMaximization.initialize!(m::QLearner, parameters)\n    m.q .= parameters.q₀\nend\n\nLaplacianExpectationMaximization.parameters(::QLearner) = (; q₀ = zeros(10, 3), η = 0., β_real = 1., γ_logit = 10.)\n\nfunction LaplacianExpectationMaximization.logp(data, m::QLearner, parameters)\n    initialize!(m, parameters)\n    (; η, β_real, γ_logit) = parameters\n    β = softplus(β_real)\n    γ = logistic(γ_logit)\n    q = m.q\n    logp = 0.\n    for (; s, a, s′, r, done) in data\n        logp += logsoftmax(β, q, s, a)\n        td_error = r + γ * findmax(view(q, s′, :))[1] - q[s, a]\n        q[s, a] += η * td_error\n    end\n    logp\nend\n\nfunction LaplacianExpectationMaximization.sample(rng, data, m::QLearner, parameters; environment)\n    (; η, β_real) = parameters\n    q = m.q\n    (; s′, done) = data[end]\n    if done\n        s′ = initial_state(rng, environment)\n    end\n    a′ = randsoftmax(rng, softplus(β_real), q, s′)\n    s′′ = transition(rng, environment, s′, a′)\n    r′ = reward(rng, environment, s′, a′, s′′)\n    (s = s′, a = a′, s′ = s′′, r = r′, done = isdone(rng, environment, s′′))\nend","category":"page"},{"location":"rl/","page":"Fitting a Q-Learner","title":"Fitting a Q-Learner","text":"Let us define the helper functions logsoftmax, randsoftmax and the environment functions initial_state, transition, reward, isdone.","category":"page"},{"location":"rl/","page":"Fitting a Q-Learner","title":"Fitting a Q-Learner","text":"using Distributions, LinearAlgebra\n\nlogsoftmax(β, q, s, a) = β * q[s, a] - logsumexp(β, view(q, s, :))\nfunction logsumexp(β, v)\n    m = β * maximum(v)\n    sumexp = zero(eltype(v))\n    for vᵢ in v\n        sumexp += exp(β * vᵢ - m)\n    end\n    m + log(sumexp)\nend\nfunction randsoftmax(rng, β, q, s)\n    m = maximum(view(q, s, :))\n    p = exp.(q[s, :] .- m)\n    p ./= sum(p)\n    rand(rng, Categorical(p))\nend\n@concrete struct Environment\n    t\n    r\nend\nfunction Environment(; rng = Random.default_rng())\n    Environment([normalize(rand(rng, 10), 1) for s in 1:10, a in 1:3],\n                randn(rng, 10, 3))\nend\ninitial_state(rng, ::Environment) = rand(rng, 1:10)\ntransition(rng, e::Environment, s, a) = rand(rng, Categorical(e.t[s, a]))\nreward(rng, e::Environment, s, a, s′) = e.r[s, a]\nisdone(rng, e::Environment, s) = s == 10","category":"page"},{"location":"rl/","page":"Fitting a Q-Learner","title":"Fitting a Q-Learner","text":"With this we can generate some artificial data and fit it.","category":"page"},{"location":"rl/","page":"Fitting a Q-Learner","title":"Fitting a Q-Learner","text":"using ComponentArrays, Random\n\nmodel = QLearner()\np = ComponentArray(parameters(model))\np.η = .15\np.β_real = 1.6\np.γ_logit = 1.8\nrng = Xoshiro(17)\ntmp = [simulate(model, p;\n                n_steps = 200, rng,\n                init = [(s = 1, a = 1, s′ = 1, r = 0., done = false)],\n                environment = Environment(; rng))\n       for _ in 1:100]\ndata = first.(tmp)\ndata_logp = sum(last.(tmp))","category":"page"},{"location":"rl/","page":"Fitting a Q-Learner","title":"Fitting a Q-Learner","text":"This is the probability with which the data was generated. Let us check the data probability under the default parameters.","category":"page"},{"location":"rl/","page":"Fitting a Q-Learner","title":"Fitting a Q-Learner","text":"population_model = PopulationModel(model, shared = (:q₀, :η, :β_real, :γ_logit))\np0 = ComponentArray(parameters(population_model))\nmc_marginal_logp(data, population_model, p0)","category":"page"},{"location":"rl/","page":"Fitting a Q-Learner","title":"Fitting a Q-Learner","text":"We see that the data probability under the default parameters is higher than under the parameter with which the data was generated. Now we maximize the log-likelihood, to find the optimal parameters for this data.","category":"page"},{"location":"rl/","page":"Fitting a Q-Learner","title":"Fitting a Q-Learner","text":"result = maximize_logp(data, population_model)\nresult.logp","category":"page"},{"location":"rl/","page":"Fitting a Q-Learner","title":"Fitting a Q-Learner","text":"The resulting data probability is indeed the highest. The fitted parameters are, however, not super close to p:","category":"page"},{"location":"rl/","page":"Fitting a Q-Learner","title":"Fitting a Q-Learner","text":"result.population_parameters","category":"page"},{"location":"rl/","page":"Fitting a Q-Learner","title":"Fitting a Q-Learner","text":"We can try fixing q₀:","category":"page"},{"location":"rl/","page":"Fitting a Q-Learner","title":"Fitting a Q-Learner","text":"result2 = maximize_logp(data, population_model, fixed = (; q₀ = zeros(10, 3)))\nresult2.logp","category":"page"},{"location":"rl/","page":"Fitting a Q-Learner","title":"Fitting a Q-Learner","text":"The data probability is a bit lower, as expected.","category":"page"},{"location":"rl/","page":"Fitting a Q-Learner","title":"Fitting a Q-Learner","text":"result2.population_parameters","category":"page"},{"location":"rl/","page":"Fitting a Q-Learner","title":"Fitting a Q-Learner","text":"The fitted parameters, however, are closer to p.","category":"page"},{"location":"reference/#Reference","page":"Reference","title":"Reference","text":"","category":"section"},{"location":"reference/#Functions-to-extend-with-a-new-model","page":"Reference","title":"Functions to extend with a new model","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"LaplacianExpectationMaximization.initialize!\nLaplacianExpectationMaximization.parameters\nLaplacianExpectationMaximization.logp\nLaplacianExpectationMaximization.sample","category":"page"},{"location":"reference/#LaplacianExpectationMaximization.initialize!","page":"Reference","title":"LaplacianExpectationMaximization.initialize!","text":"initialize!(model, parameters)\n\nInitalizes the state of the model.\n\n\n\n\n\n","category":"function"},{"location":"reference/#LaplacianExpectationMaximization.parameters","page":"Reference","title":"LaplacianExpectationMaximization.parameters","text":"parameters(model)\n\nReturns a named tuple.\n\n\n\n\n\n","category":"function"},{"location":"reference/#LaplacianExpectationMaximization.logp","page":"Reference","title":"LaplacianExpectationMaximization.logp","text":"logp(data, model, parameters)\n\nReturns log P(datamodel parameters).\n\n\n\n\n\n","category":"function"},{"location":"reference/#LaplacianExpectationMaximization.sample","page":"Reference","title":"LaplacianExpectationMaximization.sample","text":"sample(rng, data, model, parameters; kw...)\n\nTakes already generated data as input and returns a new data point. This function is called in the simulate function. Keyword arguments are passed through the simulate function.\n\n\n\n\n\n","category":"function"},{"location":"reference/#Population-model","page":"Reference","title":"Population model","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"LaplacianExpectationMaximization.PopulationModel","category":"page"},{"location":"reference/#LaplacianExpectationMaximization.PopulationModel","page":"Reference","title":"LaplacianExpectationMaximization.PopulationModel","text":"PopulationModel(model; prior = DiagonalNormalPrior(), shared = ())\n\nWrap a model for estimating population parameters. Shared parameters should be given as a tuple of symbols.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Fitting","page":"Reference","title":"Fitting","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"LaplacianExpectationMaximization.maximize_logp","category":"page"},{"location":"reference/#LaplacianExpectationMaximization.maximize_logp","page":"Reference","title":"LaplacianExpectationMaximization.maximize_logp","text":"maximize_logp(data, model, parameters = parameters(model);\n              fixed = (;)\n              coupled = [],\n              lambda_l2 = 0.,\n              hessian_ad = AutoForwardDiff(),\n              gradient_ad = AutoForwardDiff(),\n              evaluate_training = false,\n              evaluate_test_data = nothing,\n              evaluation_trigger = EventTrigger(),\n              evaluation_options = (;),\n              optimizer_options = (;),\n              optimizer = default_optimizer(model, parameters; fixed, optimizer_options...),\n              callbacks = [],\n              verbosity = 1, print_interval = 3,\n              return_g! = false,\n              kw...\n              )\n\n\n\n\n\n","category":"function"},{"location":"reference/#Optimizers","page":"Reference","title":"Optimizers","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"LaplacianExpectationMaximization.Optimizer\nLaplacianExpectationMaximization.NLoptOptimizer\nLaplacianExpectationMaximization.OptimOptimizer\nLaplacianExpectationMaximization.OptimisersOptimizer\nLaplacianExpectationMaximization.OptimizationOptimizer\nLaplacianExpectationMaximization.LaplaceEM","category":"page"},{"location":"reference/#LaplacianExpectationMaximization.Optimizer","page":"Reference","title":"LaplacianExpectationMaximization.Optimizer","text":"Optimizer(; optimizer = OptimOptimizer(Optim.LBFGS()), finetuner = nothing, fallback = OptimisersOptimizer())\n\nDefault optimizer. finetuner can be another optimizer that is called after the first optimizer finished. The fallback optimizer is called, if the optimizer or finetuner fails.\n\nCan also be constructed as\n\nOptimizer(optimizer; finetuner = nothing, fallback = OptimisersOptimizer(), kw...)\n\nwhere optimizer can be a symbol (to use NLopt), or an optimiser from Optim or Optimiser. See also NLoptOptimizer, OptimOptimizer, OptimisersOptimizer.\n\n\n\n\n\n","category":"type"},{"location":"reference/#LaplacianExpectationMaximization.NLoptOptimizer","page":"Reference","title":"LaplacianExpectationMaximization.NLoptOptimizer","text":"NLoptOptimizer(optimizer; options...)\n\nThe optimizer is a symbol (e.g. :LD_LBGFS) as specified here. For options, see NLopt options.\n\n\n\n\n\n","category":"type"},{"location":"reference/#LaplacianExpectationMaximization.OptimOptimizer","page":"Reference","title":"LaplacianExpectationMaximization.OptimOptimizer","text":"OptimOptimizer(optimizer; options...)\n\nOptimizer can be anything from subtypes.(subtypes(Optim.AbstractOptimizer)). For options, see Optim Options.\n\n\n\n\n\n","category":"type"},{"location":"reference/#LaplacianExpectationMaximization.OptimisersOptimizer","page":"Reference","title":"LaplacianExpectationMaximization.OptimisersOptimizer","text":"OptimisersOptimizer(opt; maxeval = 10^5, maxtime = Inf, min_grad_norm = 1e-8, lower_bounds = -Inf, upper_bounds = Inf)\n\nOptimizer opt can be anything from subtypes(Optimisers.AbstractRule). Optimization stops, when the L2-norm of the gradient falls below min_grad_norm or maxeval or maxtime is reached. See also Optimisers.\n\n\n\n\n\n","category":"type"},{"location":"reference/#LaplacianExpectationMaximization.OptimizationOptimizer","page":"Reference","title":"LaplacianExpectationMaximization.OptimizationOptimizer","text":"OptimizationOptimizer(optimizer, adtype, options)\n\nUses Optimization.jl. options are passed to Optimization.solve\n\nExample\n\n``` using LaplacianExpectationMaximization, Optimization, OptimizationOptimJL, ADTypes OptimizationOptimizer(LBFGS(), AutoForwardDiff(), (;))\n\n\n\n\n\n","category":"type"},{"location":"reference/#LaplacianExpectationMaximization.LaplaceEM","page":"Reference","title":"LaplacianExpectationMaximization.LaplaceEM","text":"LaplaceEM(model, Estep_optimizer = Optimizer(), derivative_threshold = 1e-3, iterations = 10, stopper = () -> false)\n\nImplements the Expectation-Maximization (EM) method with Laplace approximation, as described e.g. in Huys et al. (2012).\n\n\n\n\n\n","category":"type"},{"location":"reference/#Simulation","page":"Reference","title":"Simulation","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"LaplacianExpectationMaximization.simulate\nLaplacianExpectationMaximization.logp_tracked","category":"page"},{"location":"reference/#LaplacianExpectationMaximization.simulate","page":"Reference","title":"LaplacianExpectationMaximization.simulate","text":"simulate(\n    model,\n    parameters;\n    n_steps,\n    stop,\n    init,\n    tracked,\n    rng,\n    kw...\n)\n\n\nReturns a named tuple (; data, logp). stop(data, i) is a boolean function that depends on the sequence of simulated data and the iteration counter i. If tracked = true the state of the model is saved for every step in the simulation. Additional keyword arguments kw are passed to the sample function.\n\n\n\n\n\n","category":"function"},{"location":"reference/#LaplacianExpectationMaximization.logp_tracked","page":"Reference","title":"LaplacianExpectationMaximization.logp_tracked","text":"logp_tracked(data, model, parameters)\n\n\nReturns a names tuple (; history, logp). In the history the state of the model is saved for every step.\n\n\n\n\n\n","category":"function"},{"location":"reference/#Evaluation","page":"Reference","title":"Evaluation","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"LaplacianExpectationMaximization.mc_marginal_logp\nLaplacianExpectationMaximization.BIC_int","category":"page"},{"location":"reference/#LaplacianExpectationMaximization.mc_marginal_logp","page":"Reference","title":"LaplacianExpectationMaximization.mc_marginal_logp","text":"mc_marginal_logp(data, model::PopulationModel, params;\n                 repetitions = 20, n_samples = 10^4, rng = Random.default_rng())\n\nEstimate the marginal log probability of the data given a model by sampling from the population.\n\n\n\n\n\n","category":"function"},{"location":"reference/#LaplacianExpectationMaximization.BIC_int","page":"Reference","title":"LaplacianExpectationMaximization.BIC_int","text":"BIC_int(data, model, params; kw...)\n\n\nEstimate the Bayesian Information Criterion by sampling from the population. Keyword arguments kw are passed to mc_marginal_logp.\n\n\n\n\n\n","category":"function"},{"location":"reference/#Derivatives","page":"Reference","title":"Derivatives","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"LaplacianExpectationMaximization.gradient_logp\nLaplacianExpectationMaximization.hessian_logp","category":"page"},{"location":"reference/#LaplacianExpectationMaximization.gradient_logp","page":"Reference","title":"LaplacianExpectationMaximization.gradient_logp","text":"gradient_logp(data, model, parameters; ad = AutoEnzyme())\n\nCompute the gradient of logp.\n\n\n\n\n\n","category":"function"},{"location":"reference/#LaplacianExpectationMaximization.hessian_logp","page":"Reference","title":"LaplacianExpectationMaximization.hessian_logp","text":"hessian_logp(data, model, parameters; ad = AutoForwardDiff())\n\nCompute the hessian of logp.\n\n\n\n\n\n","category":"function"},{"location":"#LaplacianExpectationMaximization","page":"Home","title":"LaplacianExpectationMaximization","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This package implements the Expectation-Maximization (EM) algorithm with a Laplacian approximation for the E-step, as described e.g. here, for finding the maximum likelihood estimate of the parameter distribution of a model.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Assume some data mathcal D = boldsymbol x_1 ldots boldsymbol x_n was generated by sampling independently from the conditional density boldsymbol x_isim p(boldsymbol xboldsymbol theta_i), where boldsymbol theta_i are parameters sampled from a multivariate normal distribution with diagonal covariance boldsymbol theta_isimmathcal N(boldsymbol theta boldsymbol mu boldsymbolsigma). This package allows to find the maximum likelihood estimates ","category":"page"},{"location":"","page":"Home","title":"Home","text":"beginalign*\nboldsymbol mu^* boldsymbol sigma^* = argmax_boldsymbol mu boldsymbolsigmap(mathcal D  boldsymbolmu boldsymbol sigma) = argmax_boldsymbol mu boldsymbolsigmasum_i=1^nlog(p(boldsymbol x_iboldsymbolmu boldsymbolsigma)) = argmax_boldsymbol mu boldsymbolsigmasum_i=1^nlogleft(int p(boldsymbol x_iboldsymbol theta_i)mathcal N(boldsymboltheta_iboldsymbolmu boldsymbolsigma)dboldsymboltheta_iright)\nendalign*","category":"page"},{"location":"","page":"Home","title":"Home","text":"using the EM algorithm with Laplacian approximation for the E-step.","category":"page"},{"location":"#Example","page":"Home","title":"Example","text":"","category":"section"},{"location":"#Model-Definition","page":"Home","title":"Model Definition","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"For a sequence of binary values y = (y_1 ldots y_T) we define a habituating biased coin model with probability P(y) = prod_t=1^TP(y_tw_t-1) with w_t = w_t-1 + eta (y_t-1 - sigma(w_t-1)), where w_0 and eta are parameters of the model and sigma(w) = 1(1 + exp(-w)).","category":"page"},{"location":"","page":"Home","title":"Home","text":"We define the model HabituatingBiasedCoin with state variable w and extend the functions parameters, initialize!, logp and sample from LaplacianExpectationMaximization.","category":"page"},{"location":"","page":"Home","title":"Home","text":"# import LaplacianExpectationMaximization: parameters, initialize!, logp, sample # if you want to avoid writing LaplacianExpectationMaximization.logp etc. \nusing LaplacianExpectationMaximization\nusing ConcreteStructs, Distributions\n\n@concrete struct HabituatingBiasedCoin\n    w\nend\nHabituatingBiasedCoin() = HabituatingBiasedCoin(Base.RefValue(0.))\n\nfunction LaplacianExpectationMaximization.initialize!(m::HabituatingBiasedCoin, parameters)\n    m.w[] = parameters.w₀\nend\n\nLaplacianExpectationMaximization.parameters(::HabituatingBiasedCoin) = (; w₀ = 0., η = 0.)\n\nsigmoid(w) = 1/(1 + exp(-w))\n\nfunction LaplacianExpectationMaximization.logp(data, m::HabituatingBiasedCoin, parameters)\n    LaplacianExpectationMaximization.initialize!(m, parameters)\n    η = parameters.η\n    logp = 0.\n    for yₜ in data\n        ρ = sigmoid(m.w[])\n        logp += logpdf(Bernoulli(ρ), yₜ)\n        m.w[] += η * (yₜ - ρ)\n    end\n    logp\nend\n\nfunction LaplacianExpectationMaximization.sample(rng, ::Any, m::HabituatingBiasedCoin, ::Any)\n    rand(rng) ≤ sigmoid(m.w[])\nend","category":"page"},{"location":"#Generating-data","page":"Home","title":"Generating data","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Let us generate 5 sequences of 30 steps with this model.","category":"page"},{"location":"","page":"Home","title":"Home","text":"import LaplacianExpectationMaximization: simulate\n\nmodel = HabituatingBiasedCoin()\nparams = (; w₀ = .3, η = .1)\ndata = [simulate(model, params, n_steps = 30).data for _ in 1:5]","category":"page"},{"location":"#Fitting-a-single-model","page":"Home","title":"Fitting a single model","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"First we check, if gradients are properly computed for our model.","category":"page"},{"location":"","page":"Home","title":"Home","text":"import LaplacianExpectationMaximization: gradient_logp\ngradient_logp(data[1], model, params)","category":"page"},{"location":"","page":"Home","title":"Home","text":"If this fails, it is recommended to check that logp does not allocate, e.g. with","category":"page"},{"location":"","page":"Home","title":"Home","text":"using BenchmarkTools\n@benchmark LaplacianExpectationMaximization.logp($(data[1]), $model, $params)","category":"page"},{"location":"","page":"Home","title":"Home","text":"We also check if Hessians are properly computed.","category":"page"},{"location":"","page":"Home","title":"Home","text":"import LaplacianExpectationMaximization: hessian_logp\nhessian_logp(data[1], model, params)","category":"page"},{"location":"","page":"Home","title":"Home","text":"This may fail, if the model is too restrictive in its type parameters.","category":"page"},{"location":"","page":"Home","title":"Home","text":"If everything works fine we run the optimizer:","category":"page"},{"location":"","page":"Home","title":"Home","text":"import LaplacianExpectationMaximization: maximize_logp\nresult = maximize_logp(data[1], model)","category":"page"},{"location":"","page":"Home","title":"Home","text":"To inspect the state of the fitted model we can run","category":"page"},{"location":"","page":"Home","title":"Home","text":"import LaplacianExpectationMaximization: logp_tracked\nlogp_tracked(data[1], model, result.parameters).history","category":"page"},{"location":"","page":"Home","title":"Home","text":"We can also fit with some fixed parameters.","category":"page"},{"location":"","page":"Home","title":"Home","text":"result = maximize_logp(data[1], model, fixed = (; η = 0.))\nresult.parameters","category":"page"},{"location":"","page":"Home","title":"Home","text":"or with coupled parameters","category":"page"},{"location":"","page":"Home","title":"Home","text":"result = maximize_logp(data[1], model, coupled = [(:w₀, :η)])\nresult.parameters","category":"page"},{"location":"#Fitting-a-population-model","page":"Home","title":"Fitting a population model","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Now we fit all data samples with approximate EM, assuming a diagonal normal prior over the parameters.","category":"page"},{"location":"","page":"Home","title":"Home","text":"import LaplacianExpectationMaximization: PopulationModel\npop_model1 = PopulationModel(model)\nresult1 = maximize_logp(data, pop_model1)\nresult1.population_parameters","category":"page"},{"location":"","page":"Home","title":"Home","text":"Let us compare this to a model where all samples are assumed to be generated from the same parameters, i.e. the variance of the normal prior is zero.","category":"page"},{"location":"","page":"Home","title":"Home","text":"pop_model2 = PopulationModel(model, shared = (:w₀, :η))\nresult2 = maximize_logp(data, pop_model2)\nresult2.population_parameters","category":"page"},{"location":"","page":"Home","title":"Home","text":"To compare the models we look at the approximate BIC","category":"page"},{"location":"","page":"Home","title":"Home","text":"import LaplacianExpectationMaximization: BIC_int\n(model1 = BIC_int(data, pop_model1, result1.population_parameters, repetitions = 1),\n model2 = BIC_int(data, pop_model2, result2.population_parameters))","category":"page"},{"location":"","page":"Home","title":"Home","text":"We see that the second model without variance of the prior has the lower BIC. This is not surprising, given that the data was generated with identical parameters.","category":"page"}]
}
